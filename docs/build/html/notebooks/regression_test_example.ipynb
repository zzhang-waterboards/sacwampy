{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a296ea",
   "metadata": {},
   "source": [
    "# Regression test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357197d0",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The purpose of the regression test is to quickly compare an existing run and an archived run (previous run), display a series of performance metrics and highlight those metrics exceeding predefined thresholds. \n",
    "To perform a regression test, type the following command in a python editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74300b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run regression_testing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6035e07b",
   "metadata": {},
   "source": [
    "or in anaconda, type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7983f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "python regression_testing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32acb9b",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "To customize your run, the input section of 'regression_testing.py' is explained below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c629e",
   "metadata": {},
   "source": [
    "Defines a list of favorites to compare. Note that the favorites defined have to exist for both current run and the archived run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ddf5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "favorites = [\"Canal Flows\",\"COA\",\"SW Storage\",\"SWRCB IFR Flows\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd564db",
   "metadata": {},
   "source": [
    "Defines a list of scenarios to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [\"Existing\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e16f86",
   "metadata": {},
   "source": [
    "Define the thresholds for anomaly detection; comment out the metrics if not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d67cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_threshold = {\"mean squared error\":2.0,   #mean squared error\n",
    "                     #\"mape\":0.1, #mean_absolute_percentage_error\n",
    "                     \"mean error\": 2.0,  # mean error\n",
    "                     \"mean percent error\": 0.05, #mean percent error\n",
    "                     \"correcoef\":0.9, # correlation coefficient\n",
    "                     \"skill score\":0.9} # Nash-Sutcliffe-like skill score based on mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72846db9",
   "metadata": {},
   "source": [
    "Define the run names, current run can also be defined as 'Most Recent'. \n",
    "By default, comparisons between only two runs are allowed. If more runs are defined, the script will still export the favorites for all the runs but will give an error when the results are compared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce531a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = ['2024-10-24 (1)','2024-10-24 (2)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c95b94a",
   "metadata": {},
   "source": [
    "Define output path for the favorites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c097d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79377561",
   "metadata": {},
   "source": [
    "If results already exist, overwrite or not. \n",
    "\n",
    "\n",
    "favorite_unit = 'taf' # Only 'taf' and 'cfs' are implemented. When favorite units are inconsistent across different varaibles, set it to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43889345",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a82af",
   "metadata": {},
   "source": [
    "Set the output unit for favorites: only 'taf' or 'cfs' are implemented. \n",
    "If the outputs is not flow based, the unit will be unchanged.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "favorite_unit = 'taf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f2a44",
   "metadata": {},
   "source": [
    "Note that the unit conversion will slow down the script by about 10 seconds.\n",
    "If no unit convertion is required, set favorite_unit to None. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "favorite_unit = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9306907",
   "metadata": {},
   "source": [
    "When the script is run, a table called 'full_report_%s.xlsx'%scenario will be generated in ouptut_path. \n",
    "Each sheet shows the results for each performance metrics. \n",
    "The values that exceed the defined thresholds will be highlighted in Red. \n",
    "<img src=\"files/report.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
